{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Error Estimation (15 points)\n",
    "\n",
    "In this task, we will explore few ideas for estimating the generalization error (i.e. performance of the model in the production). \n",
    "\n",
    "The code for this task is inside `error_estimation.py`. You will flesh out the function `estimate_error`. This function has three arguments. The `dataset_config` stores the training, validation, testing and production data. The `ml_model` is a scikit-learn classifier (one of decision tree, KNN and Naive Bayes). So you can call the `fit` and `predict` functions on them. Finally, `error_estimator` is a class that provides which algorithms to try and stores the error estimates. \n",
    "\n",
    "You will implement 5 different approaches for estimating the error of the model on production data. Note each of these approaches should not take more than 2-3 lines of code. The approaches are:\n",
    "\n",
    "1. TRAIN: This approach estimates that the accuracy on the validation data is the same as the production data. So, you have to fit the model on training data and get the accuracy on the test data.\n",
    "\n",
    "2. TRAIN_VAL: This approach estimates that the accuracy on the training+validation data is the same as the production data. So, you have to fit the model on training+validation data and get the accuracy on the test data. The dataset_config already has a variable that pools training and validation data.\n",
    "\n",
    "3. CV_TRAIN_VAL: This approach is same as TRAIN_VAL except that you use cross validation. Use the scikit-learn's cross_val_score function (and set scoring=accuracy). By default, scikit-learn uses a 5-fold cross validation and will return the accuracy on each of the five fold. Just compute the mean value of this and use that as the estimate. \n",
    "\n",
    "4. BOOTSTRAP_632: This approach uses a more complex approach using Bootstrap. You can use the function `bootstrap_point632_score` from [here](https://rasbt.github.io/mlxtend/user_guide/evaluate/bootstrap_point632_score/). There are two key things to be aware. First, set n_splits to NUM_BOOTSTRAP_TRIALS and random_seed to utils.ANSWER_TO_EVERYTHING so that the result is reproducible. \n",
    "\n",
    "5. BOOTSTRAP_OOB: This is the same as `bootstrap_point632_score`. But 'oob' as the method to the `bootstrap_point632_score` function. Both these methods output confidence intervals (see the API documentation of `bootstrap_point632_score`). So, you can use that code to estimate the 95% confidence intervals. \n",
    " \n",
    "\n",
    " You can test the code using \n",
    "\n",
    "> rye test -- -m t4_error_estimator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
