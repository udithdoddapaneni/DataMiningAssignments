{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/udith/labs and projects/Data Mining Assignments/PA4/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoMLWithAutoGluon:\n",
    "    def __init__(self):\n",
    "        self.predictor:TabularPredictor|None = None\n",
    "    def train_automl_model(self, dataset:pd.DataFrame, target:str, time_limit=120):\n",
    "        self.predictor = TabularPredictor(label=target)\n",
    "        self.predictor.fit(dataset, time_limit=time_limit)\n",
    "    def test_automl_model(self, dataset:pd.DataFrame, target:str):\n",
    "        y_true = dataset[target]\n",
    "        y_pred = self.predictor.predict(dataset)\n",
    "        return self.predictor.eval_metric(y_true, y_pred)\n",
    "    def print_leaderboard(self):\n",
    "        print(self.predictor.leaderboard())\n",
    "    def print_feature_importance(self, dataset):\n",
    "        print(self.predictor.feature_importance(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_gender</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>previous_loan_defaults_on_file</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Master</td>\n",
       "      <td>71948.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>16.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>561</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High School</td>\n",
       "      <td>12282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OWN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>504</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High School</td>\n",
       "      <td>12438.0</td>\n",
       "      <td>3</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>12.87</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>635</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>79753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>675</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Master</td>\n",
       "      <td>66135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>14.27</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>586</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age person_gender person_education  person_income  person_emp_exp  \\\n",
       "0        22.0        female           Master        71948.0               0   \n",
       "1        21.0        female      High School        12282.0               0   \n",
       "2        25.0        female      High School        12438.0               3   \n",
       "3        23.0        female         Bachelor        79753.0               0   \n",
       "4        24.0          male           Master        66135.0               1   \n",
       "\n",
       "  person_home_ownership  loan_amnt loan_intent  loan_int_rate  \\\n",
       "0                  RENT    35000.0    PERSONAL          16.02   \n",
       "1                   OWN     1000.0   EDUCATION          11.14   \n",
       "2              MORTGAGE     5500.0     MEDICAL          12.87   \n",
       "3                  RENT    35000.0     MEDICAL          15.23   \n",
       "4                  RENT    35000.0     MEDICAL          14.27   \n",
       "\n",
       "   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n",
       "0                 0.49                         3.0           561   \n",
       "1                 0.08                         2.0           504   \n",
       "2                 0.44                         3.0           635   \n",
       "3                 0.44                         2.0           675   \n",
       "4                 0.53                         4.0           586   \n",
       "\n",
       "  previous_loan_defaults_on_file  loan_status  \n",
       "0                             No            1  \n",
       "1                            Yes            0  \n",
       "2                             No            1  \n",
       "3                             No            1  \n",
       "4                             No            1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"datasets/loan_data.csv\")\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504000 126000 630000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "train, test = pd.DataFrame(train, columns=dataset.columns), pd.DataFrame(test, columns=dataset.columns)\n",
    "\n",
    "print(train.size, test.size, dataset.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241117_151758\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.1.2b20241117\n",
      "Python Version:     3.11.9\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #48~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon Oct  7 11:24:13 UTC 2\n",
      "CPU Count:          16\n",
      "Memory Avail:       7.78 GB / 14.86 GB (52.3%)\n",
      "Disk Space Avail:   9.38 GB / 118.32 GB (7.9%)\n",
      "\tWARNING: Available disk space is low and there is a risk that AutoGluon will run out of disk during fit, causing an exception. \n",
      "\tWe recommend a minimum available disk space of 10 GB, and large datasets may require more.\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium_quality'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='best_quality'   : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks. Default time_limit=3600.\n",
      "\tpresets='high_quality'   : Strong accuracy with fast inference speed. Default time_limit=3600.\n",
      "\tpresets='good_quality'   : Good accuracy with very fast inference speed. Default time_limit=3600.\n",
      "\tpresets='medium_quality' : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 120s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20241117_151758\"\n",
      "Train Data Rows:    36000\n",
      "Train Data Columns: 13\n",
      "Label Column:       loan_status\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    7982.52 MB\n",
      "\tTrain Data (Original)  Memory Usage: 13.07 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 6 | ['person_age', 'person_income', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', ...]\n",
      "\t\t('int', [])    : 2 | ['person_emp_exp', 'credit_score']\n",
      "\t\t('object', []) : 5 | ['person_gender', 'person_education', 'person_home_ownership', 'loan_intent', 'previous_loan_defaults_on_file']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 3 | ['person_education', 'person_home_ownership', 'loan_intent']\n",
      "\t\t('float', [])     : 6 | ['person_age', 'person_income', 'loan_amnt', 'loan_int_rate', 'loan_percent_income', ...]\n",
      "\t\t('int', [])       : 2 | ['person_emp_exp', 'credit_score']\n",
      "\t\t('int', ['bool']) : 2 | ['person_gender', 'previous_loan_defaults_on_file']\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 2.37 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.06944444444444445, Train Rows: 33500, Val Rows: 2500\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 119.87s of the 119.86s of remaining time.\n",
      "\t0.8268\t = Validation score   (accuracy)\n",
      "\t1.21s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 118.63s of the 118.63s of remaining time.\n",
      "\t0.8276\t = Validation score   (accuracy)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 118.53s of the 118.52s of remaining time.\n",
      "\t0.9188\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 117.98s of the 117.97s of remaining time.\n",
      "\t0.9332\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ... Training model for up to 117.36s of the 117.36s of remaining time.\n",
      "\t0.9208\t = Validation score   (accuracy)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 116.09s of the 116.09s of remaining time.\n",
      "\t0.9212\t = Validation score   (accuracy)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 114.79s of the 114.79s of remaining time.\n",
      "\t0.9284\t = Validation score   (accuracy)\n",
      "\t6.68s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 108.1s of the 108.1s of remaining time.\n",
      "\t0.916\t = Validation score   (accuracy)\n",
      "\t0.74s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 107.07s of the 107.07s of remaining time.\n",
      "\t0.9188\t = Validation score   (accuracy)\n",
      "\t0.73s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 106.05s of the 106.05s of remaining time.\n",
      "\t0.9168\t = Validation score   (accuracy)\n",
      "\t20.71s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 85.3s of the 85.3s of remaining time.\n",
      "\t0.9336\t = Validation score   (accuracy)\n",
      "\t0.53s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 84.76s of the 84.76s of remaining time.\n",
      "\t0.9144\t = Validation score   (accuracy)\n",
      "\t18.79s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 65.96s of the 65.95s of remaining time.\n",
      "\t0.936\t = Validation score   (accuracy)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 119.87s of the 64.91s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMLarge': 0.75, 'KNeighborsDist': 0.25}\n",
      "\t0.9364\t = Validation score   (accuracy)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 55.21s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 109519.9 rows/s (2500 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (2500 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20241117_151758\")\n"
     ]
    }
   ],
   "source": [
    "model =  AutoMLWithAutoGluon()\n",
    "model.train_automl_model(train, \"loan_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9325555555555556"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test_automl_model(test, target=\"loan_status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  model  score_val eval_metric  pred_time_val   fit_time  \\\n",
      "0   WeightedEnsemble_L2     0.9364    accuracy       0.022827   1.167248   \n",
      "1         LightGBMLarge     0.9360    accuracy       0.005808   0.996938   \n",
      "2               XGBoost     0.9336    accuracy       0.008931   0.527533   \n",
      "3              LightGBM     0.9332    accuracy       0.007315   0.586140   \n",
      "4              CatBoost     0.9284    accuracy       0.002805   6.678607   \n",
      "5      RandomForestEntr     0.9212    accuracy       0.036833   1.138601   \n",
      "6      RandomForestGini     0.9208    accuracy       0.035609   1.091131   \n",
      "7            LightGBMXT     0.9188    accuracy       0.006198   0.532670   \n",
      "8        ExtraTreesEntr     0.9188    accuracy       0.037059   0.729455   \n",
      "9       NeuralNetFastAI     0.9168    accuracy       0.018558  20.708769   \n",
      "10       ExtraTreesGini     0.9160    accuracy       0.036160   0.736362   \n",
      "11       NeuralNetTorch     0.9144    accuracy       0.014999  18.785256   \n",
      "12       KNeighborsDist     0.8276    accuracy       0.016372   0.075818   \n",
      "13       KNeighborsUnif     0.8268    accuracy       0.017618   1.212347   \n",
      "\n",
      "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                 0.000647           0.094491            2       True   \n",
      "1                 0.005808           0.996938            1       True   \n",
      "2                 0.008931           0.527533            1       True   \n",
      "3                 0.007315           0.586140            1       True   \n",
      "4                 0.002805           6.678607            1       True   \n",
      "5                 0.036833           1.138601            1       True   \n",
      "6                 0.035609           1.091131            1       True   \n",
      "7                 0.006198           0.532670            1       True   \n",
      "8                 0.037059           0.729455            1       True   \n",
      "9                 0.018558          20.708769            1       True   \n",
      "10                0.036160           0.736362            1       True   \n",
      "11                0.014999          18.785256            1       True   \n",
      "12                0.016372           0.075818            1       True   \n",
      "13                0.017618           1.212347            1       True   \n",
      "\n",
      "    fit_order  \n",
      "0          14  \n",
      "1          13  \n",
      "2          11  \n",
      "3           4  \n",
      "4           7  \n",
      "5           6  \n",
      "6           5  \n",
      "7           3  \n",
      "8           9  \n",
      "9          10  \n",
      "10          8  \n",
      "11         12  \n",
      "12          2  \n",
      "13          1  \n"
     ]
    }
   ],
   "source": [
    "model.print_leaderboard()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "The best model is WeightedEnsemble_L2 which, as we see, outperforms even neural networks like NeuralNetFastAI and NeuralNetTorch while\n",
    "taking significantly less time compared to them\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 13 features using 5000 rows with 5 shuffle sets...\n",
      "\t3.78s\t= Expected runtime (0.76s per shuffle set)\n",
      "\t2.08s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                importance    stddev       p_value  n  \\\n",
      "previous_loan_defaults_on_file     0.10076  0.003910  2.715554e-07  5   \n",
      "loan_int_rate                      0.04744  0.004297  7.992919e-06  5   \n",
      "person_income                      0.04524  0.003877  6.406979e-06  5   \n",
      "loan_percent_income                0.04076  0.002242  1.094674e-06  5   \n",
      "person_home_ownership              0.02952  0.001869  1.916670e-06  5   \n",
      "loan_intent                        0.01508  0.002524  9.079747e-05  5   \n",
      "loan_amnt                          0.00924  0.001769  1.534985e-04  5   \n",
      "credit_score                       0.00500  0.001594  1.087208e-03  5   \n",
      "person_age                         0.00184  0.000829  3.852211e-03  5   \n",
      "person_emp_exp                     0.00092  0.000769  2.779590e-02  5   \n",
      "person_gender                      0.00048  0.000363  2.089734e-02  5   \n",
      "cb_person_cred_hist_length         0.00028  0.000460  1.227460e-01  5   \n",
      "person_education                  -0.00024  0.000607  7.868414e-01  5   \n",
      "\n",
      "                                p99_high   p99_low  \n",
      "previous_loan_defaults_on_file  0.108811  0.092709  \n",
      "loan_int_rate                   0.056288  0.038592  \n",
      "person_income                   0.053222  0.037258  \n",
      "loan_percent_income             0.045377  0.036143  \n",
      "person_home_ownership           0.033368  0.025672  \n",
      "loan_intent                     0.020278  0.009882  \n",
      "loan_amnt                       0.012882  0.005598  \n",
      "credit_score                    0.008282  0.001718  \n",
      "person_age                      0.003548  0.000132  \n",
      "person_emp_exp                  0.002504 -0.000664  \n",
      "person_gender                   0.001228 -0.000268  \n",
      "cb_person_cred_hist_length      0.001228 -0.000668  \n",
      "person_education                0.001009 -0.001489  \n"
     ]
    }
   ],
   "source": [
    "model.print_feature_importance(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The most important feature was previous_loan_defaults_on_file. If a user has defaulted on previous loans then he is much less likely to get a loan again</p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
